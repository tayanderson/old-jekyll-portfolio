<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Expressive Face Robot</title>
  <meta name="description" content="Beginning StagesOur purpose for this project was to create a robot that could respond to its user’s emotions and observe the human-robot interaction. We want...">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="http://yourdomain.com/projects/project6.html">

  <link type="application/atom+xml" rel="alternate" href="http://yourdomain.com/feed.xml" title="Taylor Anderson" />
</head>


  <body>

    <main class="main" aria-label="Content">

<!-- 	<a href="javascript:void(0)" class="icon">
	<div class="hamburger">
	  <div class="menui top-menu"></div>
	  <div class="menui mid-menu"></div>
	  <div class="menui bottom-menu"></div>
	</div>
	<div class="hamburger-bg"></div>
	</a>

	
		<div class="site-title">{ Taylor Anderson }</div>
	

    <nav class="main-nav">

    <div class="outter-wrapper">
    	<ul class="main-nav-list middle-wrapper">
		    <li><a href="/"><h1>Home</h1></a></li>
		    <li><a href="/work.html"><h1>Work</h1></a></li>
		    <li><a href="/about.html"><h1>About + Contact</h1></a></li>
	  	</ul>
	  	</div>
	</nav> -->

		<a href="javascript:void(0)" class="icon">
	<div class="hamburger">
	  <div class="menui top-menu"></div>
	  <div class="menui mid-menu"></div>
	  <div class="menui bottom-menu"></div>
	</div>
	<div class="hamburger-bg"></div>
	</a>

	
		<div class="site-title">{ Taylor Anderson }</div>
	

    <nav class="main-nav">

    <div class="outter-wrapper">
    	<ul class="main-nav-list middle-wrapper">
		    <li><a href="/"><h1>Home</h1></a></li>
		    <li><a href="/work.html"><h1>Work</h1></a></li>
		    <li><a href="/about.html"><h1>About + Contact</h1></a></li>
	  	</ul>
	  	</div>
	</nav>

	<div class="main-container animsition">

      <div class="container">

  <div class="row">
          <div class="PageNavigation">
        
          <a class="prev" href="/projects/project5.html">&laquo; Previous</a>
        
        
          <a class="next" href="/projects/project7.html">Next &raquo;</a>
        
      </div>
  </div>
  
  <div class="row row-padding">
    <div class="seven columns">

      <h2>Expressive Face Robot</h2>
      <p>The purpose for this project was to create an expressive robot prototype and analyze the human-robot interaction. The Expressive Face Robot is a robot that can display facial emotions. My team and I created a prototype using Raspberry Pi. The exterior of the prototype was 3D-printed.</p>
      </div>

    <div class="four columns offset-by-one side-info">
      <h6>Client: <span>Academic</span></h6>
      <h6>Project Type: <span>Human-Robot Interaction Study</span></h6>
      <h6>Responsibilities: <span>Research, Programming, 3D Printing, Physical Components</span></h6>
      <h6>Date Completed: <span>Fall 2015</span></h6>
    </div>
  </div>

  <div class="row row-padding u-max-full-width">
    <img src="../assets/images/project-imgs/project6/main.png" class="indiv-proj-img">
  </div>

  <h5 id="beginning-stages">Beginning Stages</h5>
<p>Our purpose for this project was to create a robot that could respond to its user’s emotions and observe the human-robot interaction. We wanted to know how people would feel about a robot that could read their emotions and respond accordingly and how would they use it.</p>

<p>Thinking about its potential uses, we designed two different designs: A more general design that could be used in a variety of applications and a more specific design that could be used as more of a emotional companion or a companion for children.</p>

<p>Technical-wise, we decided to use a Raspberry Pi and a TFL Screen for the “face” of the robot. The robot’s expressions would display on the screen.</p>

<p><img src="../assets/images/project-imgs/project6/2015-11-17 10.29.31.jpg" class="indiv-proj-img" /></p>

<h5 id="development--physical-computing">Development + Physical Computing</h5>
<p>Once we knew what we wanted to do, I started building the prototype. I was in charge of all the hardware and programming parts of the project.</p>

<p>While initially, we wanted the robot to be able to sense the user’s emotions, we, unfortunately, had to simplify that feature because of time constraints. So, we opted for more of a manual way of telling the robot what emotion they are feeling by pushing certain buttons (happy, angry, sad, etc.).</p>

<p>The main (and hardest) part of the hardware portion of the project was getting the screen working with the Raspberry Pi. It took me several hours to get the screen working and displaying what I wanted it to. To do this, I had to install a lot things on the Raspberry Pi to get it talking to the screen.</p>

<p>Once I got the screen working, next I started working on making the buttons work with the screen. Each button was supposed to display a different emotion on the screen. I used a breadboard to get the buttons working before I soldered them to the screen.</p>

<p>As for the exterior of the robot, we decided to 3D print it because it was the easiest way to get all the hardware components to fit exactly how we wanted them to. We had to do several iterations of each design before we got them the way we wanted. We then made it a little “cuter” by adding some fluff to the exterior.</p>

<p><img src="../assets/images/project-imgs/project6/circuit1.jpg" class="indiv-proj-img" /></p>

<h5 id="finished-prototype">Finished Prototype</h5>
<p>While our prototype wasn’t perfect, it was a good start for us if we wanted to do further research in this area of understanding the human-robot interaction between humans and expressive robots.</p>

<p>If I were to continue with this project, I would look further into adding a emotion sensing function for the robot. It would be a huge improvement if the robot could read the user’s facial expressions or body language and behave depending on that. That would require us to add some sort of camera or sensor that is programmed to analyze the user’s face and body language to determine what emotion the user is expressing.</p>

<p>While that would improve the overall function of the robot, it would also raise some ethical/moral concerns. The robot would always be watching the user, which may make the user uncomfortable. If I were to do this, I must first address these possible issues to make the user more comfortable and more willing to use the robot.</p>


  <div class="spacer"></div>
    <div class="pg-nav-mobile">
    
      <a class="prev" href="/projects/project5.html"><i class="fa fa-chevron-left fa-2x" aria-hidden="true"></i></a>
    
    <span>Expressive Face Robot</span>
    
      <a class="next" href="/projects/project7.html"><i class="fa fa-chevron-right fa-2x" aria-hidden="true"></i></a>
    
  </div>

</div>

    </div>

    </main>

    <script   src="https://code.jquery.com/jquery-3.1.1.min.js"   integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="   crossorigin="anonymous"></script>

<script src="https://use.fontawesome.com/273bbb70ca.js"></script>
<!-- animsition.js -->
<script src="/assets/js/animsition.min.js" type="text/javascript"></script>

<script src="/assets/js/app.js" type="text/javascript"></script>

  </body>

</html>
